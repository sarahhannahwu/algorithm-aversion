---
title: "systematic review"
output: html_document
date: "2024-08-13"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import libraries

```{r}
library(tidyverse)
library(dplyr)
library(kableExtra)
library(colorspace)
library(EnvStats)
library(ggrepel)
library(treemapify)
library(wesanderson)
library(ggsci)
library(patchwork)
library(webshot2)
library(ggpubr)
library(sjstats)
library(janitor)
library(rlang)
library(magick)
```

## Import csv of coded search results

```{r}
# coded_articles <- read_csv("Inclusion_exclusion coding - mendeley_export.csv")
```

```{r}
# Identify remaining duplicates. These were all coded as irrelevant.

titles_abstracts <- coded_articles %>% 
  select(title, abstract)  
  
duplicates <- titles_abstracts %>% 
  group_by_all() %>% 
  filter(n() > 1) %>% 
  ungroup()

# Limit to unique entries
# distinct <- coded_articles %>% 
#   distinct(title) %>% 
#   filter()

# Count number of included articles
coded_articles %>% 
  count(`Inclusion: (1) Yes (2) No, not English, (3) No, not focused on AI vs. human, (4) No, other reasons`)

# Filter for relevant articles (1st round of coding). Manually go through and remove any remaining duplicates. (Initially not identified because of slight punctuation and case differences.) Use str_to_title() to convert all titles to title case
relevant_articles <- coded_articles %>% 
  filter(`Inclusion: (1) Yes (2) No, not English, (3) No, not focused on AI vs. human, (4) No, other reasons` == 1) %>% 
  filter(!(ID %in% c("ID-1355", "ID-291", "ID-264", "ID-109", "ID-137", "ID-1295", "ID-1342", "ID-144", "ID-1134", "ID-127", "ID-459", "ID-025", "ID-023", "ID-1272", "ID-1322", "ID-1444"))) %>% 
  mutate(title = str_to_title(title))


write_csv(relevant_articles, "2024_complete_list.csv")

```

```{r}
# Count proportion of each type of method for the relevant articles
relevant_articles %>% 
  count(`Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews`) 

# Look at represented domains. It might be more informative to group into fewer buckets. For example, 'healthcare' and 'medical' could be combined into one category. 'Art' and 'visual art' could be combined. 
relevant_articles %>% 
  count(domain) %>% 
  print(n = 90)

# See the range of publication years
relevant_articles %>% 
  summarize(oldest_paper = min(year),
            newest_paper = max(year))

write_csv(relevant_articles, "1st_round_coding.csv")
```

```{r}
# Import spreadsheet of articles from ICA 2023 meta-analysis
old_articles <- read_csv("2nd_round_coding_2023_ICA.csv") %>% 
  rename("title" = "Article name",
         "domain" = "Task Domain",
         "first_author_last_name" = "First Author Last Name",
         "notes" = "Notes")

# See how many unique entries I added. 
new_articles <- anti_join(relevant_articles, old_articles, by = "title")

# Recode methods and domains in new list
# Last line uses string manipulation to only include first author's last name
new_articles_recoded <- new_articles %>% 
  mutate(Method = case_when(`Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "1" ~ "Quantitative",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "2" ~ "Qualitative",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "3" ~ "Review",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` %in% c("1, 2", NA) ~ "Other")) %>% 
  relocate(Method, .after = `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews`) %>% 
  mutate(first_author_last_name = if_else(str_detect(author, "and") == TRUE, str_extract(author, "\\b(\\w+)\\b(?=\\s+and\\b)"), str_extract(author, "\\b([\\w-]+)\\b(?=[^\\w-]*$)"))) %>% 
  mutate(year = as.factor(year))

# Check domains from old list
old_articles %>% 
  count(Field)

old_articles %>% 
  filter(Field == "business") %>% 
  print(n = 34)

# Check domains from new list
new_articles_recoded %>% 
  count(domain) %>% 
  print(n = 82)

# Check distribution of publication years
ggplot(new_articles_recoded, aes(x=year)) +
  geom_histogram(fill = "#f9da78", color = "white", stat = "count") +
  theme(axis.title = element_text(size = 14)) +
  labs(x="Year",
       y="Count")
  

```

```{r}
# Join old and new list to create 'Update on 2023 ICA 2nd round coding'
merged_list <- bind_rows(old_articles, new_articles_recoded)

# Delete unnecessary columns
merged_list_cleaned <- merged_list %>% 
  select(-c(author, `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews`, `Article ID_Old`, `Inclusion: (1) Yes (2) No, not English, (3) No, not focused on AI vs. human, (4) No, other reasons`))


# Export for use in Google Sheets
write_csv(merged_list_cleaned, "update_on_2023_ICA_2nd_round_coding.csv")

```

```{r}
# Create a merged list called '2024 + 2023 first round of coding' with duplicates removed. This will probably be a smaller file

# Import csv
ICA_1st_round_coding <- read_csv("2023_1st_round_coding.csv") %>% 
  rename("title" = "Article Title",
         "first_author_last_name" = "First Author Last Name",
         "Statistics" = "Does this paper have statistical methods",
         "Method" = "Method (1) experiment, (2) survey, (3) review, (4) other") %>% 
  mutate(title = str_to_title(title),
         Year = as.factor(Year))

# Multiple rows could refer to the same paper because each study is given its own row. Check to see how many *papers* there are
ICA_1st_round_coding %>% 
  distinct(title)

# There are 224 papers.
```


```{r}
# See how many unique entries I added. Rename columns so they correctly bind with old list.
unique_new_based_on_ICA_1st_round <- anti_join(relevant_articles, ICA_1st_round_coding, by = "title") 

unique_new_recoded <- unique_new_based_on_ICA_1st_round %>% 
  mutate(Method = case_when(`Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "1" ~ "quantitative",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "2" ~ "qualitative",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "3" ~ "review",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` %in% c("1, 2", NA) ~ "Other")) %>% 
  rename("Statistics" = `Statistics: (1) yes, (2) no`,
         "Journal" = "journal",
         "Year" = "year") %>% 
  mutate(Statistics = case_when(Statistics == "1" ~ "Yes",
                                Statistics == "2" ~ "No")) %>% 
  relocate(Method, .after = `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews`) %>% 
  mutate(first_author_last_name = if_else(str_detect(author, "and") == TRUE, str_extract(author, "\\b(\\w+)\\b(?=\\s+and\\b)"), str_extract(author, "\\b([\\w-]+)\\b(?=[^\\w-]*$)"))) %>% 
  mutate(title = str_to_title(title)) %>% 
  mutate(Year = as.factor(Year))

# I added 185 unique articles. Export and get pdfs
write_csv(unique_new_recoded, "algorithm_aversion_papers_8.20.24.csv")

# Check distribution of publication years
ggplot(unique_new_recoded, aes(x=Year)) +
  geom_histogram(fill = "#f9da78", color = "white", stat = "count") +
  theme(axis.title = element_text(size = 14)) +
  labs(x="Year",
       y="Count")
```


```{r}
# Join ICA 1st round coding + unique entries to create '2024 + 2023 first round of coding'
# Delete unnecessary columns

merged_based_on_ICA_1st_round <- bind_rows(ICA_1st_round_coding, unique_new_recoded) %>% 
    select(-c(author, `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews`, `Inclusion: (1) Yes (2) No, not English, (3) No, not focused on AI vs. human, (4) No, other reasons`))


# # Distribution of publication years
# merged_based_on_ICA_1st_round %>% 
#   filter(Year > 2014) %>% 
#   ggplot(aes(x = Year)) +
#   geom_histogram(bins = 7)

# Export
write_csv(merged_based_on_ICA_1st_round, "2024_+_2023_1st_round_coding.csv")

# 185 new + 224 old = 409
```

```{r}
# Import merged document with Sunny's second round of coding

merged_2nd_round_coding <- read_csv("2024_+_2023_2nd_round_coding_fixed_authors.csv")  %>% 
    rename("Sunny_note" = "...16",
         "title" = "title...2",
         "Sunny_coding" = "2024 systematic review inclusion and exclusion") 

```

```{r}
# Remove rows that are coded as irrelevant AND are not useful for the introduction of the paper. 
excluded_after_2nd_round <- merged_2nd_round_coding %>% 
  filter((Sunny_coding == "Exclude" & is.na(Sunny_note))) 

# Also remove duplicates
included_after_2nd_round <- anti_join(merged_2nd_round_coding, excluded_after_2nd_round) %>% 
  filter(Sunny_coding %in% c("Include", "Exclude", NA)) 

removed_duplicates_after_2nd_round <- included_after_2nd_round %>% 
  filter(!(new_list_ID %in% c("ID-293", "ID-1274"))) %>% 
  filter(!(first_author_last_name == "Bogert E, Lauharatanahirun N, Schecter A." & `Field/Discipline` == "Creative")) %>% 
  filter(!(first_author_last_name %in% c("Commerford, B.P.", "Commerford, Benjamin P.; Dennis, Sean A.; Joe, Jennifer R.; Ulla, Jenny W."))) 

# Check how many papers there are for meta-analysis
removed_duplicates_after_2nd_round %>% 
  filter(Sunny_coding %in% c("Include", NA)) %>% 
  distinct(title) 


```

```{r}
# For papers with more than one study, merge rows so that each row represents one paper. Sum sample sizes, combine all domains into one cell, etc. 

# Fill empty cells with publication year and journal using the helpful function fill()

merged_sample_sizes_tasks <- removed_duplicates_after_2nd_round %>% 
  mutate(Journal = str_to_title(Journal)) %>% 
  group_by(first_author_last_name, title) %>% 
  fill(Year, Journal, Sunny_coding) %>% 
  filter(Sunny_coding == "Include") %>% 
  mutate(`Sample Size` = if_else(str_detect(`Sample Size`, "[:alpha:]"), NA, `Sample Size`)) %>% 
  mutate(`Sample Size` = as.numeric(`Sample Size`)) %>%
  unite(col = "Field_Domain", c(`Field/Discipline`, domain), sep = ", ", na.rm = TRUE) %>% 
  unite(col = "country", c(Region, city_country), sep = ";", na.rm = TRUE) %>% 
  group_by(first_author_last_name, title) %>% 
  mutate(all_DVs = paste0(`Outcome variables`, collapse = "; "),
         all_tasks = paste0(`Task type`, collapse = "; ")) %>%
  mutate(all_DVs = str_remove(all_DVs, "NA; "),
         all_tasks = str_remove(all_tasks, "NA; ")) %>% 
  group_by(first_author_last_name, title) %>% 
  mutate(total_sample_size = sum(`Sample Size`)) %>% 
  group_by(first_author_last_name, title) %>% 
  select(-(title...14)) %>% 
  mutate(first_author_last_name = str_extract(first_author_last_name, "[^,]+")) %>% 
  arrange(first_author_last_name) 

one_paper_per_row <- merged_sample_sizes_tasks %>% 
  filter(is.na(study))
# Export to fix manually in Google Sheets

write_csv(one_paper_per_row, "merged_sample_sizes_tasks.csv")


```

```{r}
# Analyze distribution of publication years from working table
working_table <- read_csv("working_table_Sep11.csv") %>% 
  mutate(Year = as.factor(Year)) %>% 
  filter(!is.na(Year)) %>% 
  filter(`Sunny notes` == "Include")

ggplot(working_table, aes(x=Year)) +
  geom_histogram(fill = "#f9da78", color = "white", stat = "count") +
  theme(axis.title = element_text(size = 14)) +
  labs(x="Year",
       y="Count")

```

## Make a nice table that summarizes all the included papers

```{r}
sample_table <- working_table %>% 
  filter(`Sunny notes` == "Include") %>% 
  select(first_author_last_name, title, Year, Journal, Method, total_sample_size, Field_Domain, Algorithm_orientations, task_objectivity) %>% 
  rename("First Author" = first_author_last_name,
         "Title" = title,
         "N" = total_sample_size,
         "Field" = Field_Domain,
         "Algorithm Orientations" = Algorithm_orientations,
         "Task Objectivity" = task_objectivity) %>% 
  mutate(Method = str_to_title(Method)) %>% 
  mutate(Method = if_else(`First Author` == "Aljuneidi", "Interviews", Method)) %>% 
  mutate(N = as.numeric(N))

sample_table %>% 
  kbl() %>% 
  kable_paper("striped")
```

```{r}
ggplot(sample_table, aes(x = Field)) +
  geom_bar() +
  coord_flip()

# Visualize year, author, sample size, and method
ggplot(sample_table, aes(x=`First Author`, y=Year, size=N, color=Method)) +
  geom_point() +
  coord_flip()

# Need to reduce number of fields to make the patterns more clear
ggplot(sample_table, aes(x = Method, fill = Field)) +
  geom_bar()

sample_table %>% 
  mutate(Field = if_else(str_detect(Field, "Medical"), "Medical", Field),
         Field = if_else(str_detect(Field, "Tech"), "Technology", Field),
         Field = if_else(str_detect(Field, "Finance"), "Business", Field)) %>% 
  ggplot(aes(x=Field, fill=Method)) +
  geom_bar() +
  coord_flip()
```

## I finished coding 175 articles. Now, double-checking work here!

```{r}
# Import coded 175 articles. 

coded_table <- read_csv("working_table_Oct4.csv")

# I see some gaps in agent task and some of the algorithm types near the bottom need to be recoded to use the exact wording in the paper.
```


```{r}
# Get frequencies of aversion, appreciation

coded_table %>% 
  count(Algorithm_orientations) %>% 
  mutate(prop = n/sum(n))

# Change the classes of objects
coded_table_classes <- coded_table %>% 
  drop_na(task_objectivity, Type_of_human_manipulated, N) %>% 
  mutate(Type_of_human_manipulated = if_else(Type_of_human_manipulated == "Expert", "Experts", Type_of_human_manipulated)) %>% 
  mutate(N = as.numeric(N)) %>% 
  mutate(Algorithm_orientations = as.factor(Algorithm_orientations)) %>% 
  mutate(Algorithm_orientations = fct_relevel(Algorithm_orientations, c("Algorithm aversion", "Algorithm appreciation", "Both", "Neutral"))) %>% 
  mutate(Type_of_human_manipulated = fct_relevel(Type_of_human_manipulated, c("Experts", "Laypeople", "Both", "None"))) %>% 
  mutate(task_objectivity = as.factor(task_objectivity),
         task_objectivity = fct_relevel(task_objectivity, c("Objective", "Combined", "Subjective")))

# Combinations of task objectivity and human comparison
ggplot(coded_table_classes, aes(x=task_objectivity, y=Type_of_human_manipulated, color=Algorithm_orientations)) +
  geom_point(alpha=0.5) +
  geom_jitter() +
  theme_minimal() +
  theme(panel.grid = element_blank())
```

```{r}
# Remake table
coded_table %>% 
  select(first_author_last_name, Year, Method, theory_framework, task_objectivity, Type_of_human_manipulated, Algorithm_orientations, Summary_of_findings) %>% 
  rename("First Author" = first_author_last_name,
         "Algorithm Orientations" = Algorithm_orientations,
         "Task Objectivity" = task_objectivity,
         "Human Comparison" = Type_of_human_manipulated,
         "Theoretical Framework" = theory_framework,
         "Summary of Findings" = Summary_of_findings) %>% 
  mutate(Method = str_to_title(Method)) %>% 
  kbl() %>% 
  kable_paper("striped")
```

```{r}
# Fields 
coded_table %>% 
  count(journal_field) %>% 
  arrange(desc(n)) %>% 
  print(n=34)

# Methods
coded_table %>% 
  count(Method) %>% 
  arrange(desc(n))

# Graph of methods. Good colors could be red for aversion, yellow for appreciation, orange for both, silver for neutral
coded_table_classes %>% 
  filter(Method %in% c("experiment", "survey", "mixed-methods", "interviews")) %>% 
  ggplot(aes(x=Method, fill=Algorithm_orientations)) +
  geom_bar(position = "fill") + 
  labs(y="Proportion") +
  scale_fill_manual(name="Algorithm Orientation",
                    values = c("#9D0208", "#FFBA08", "#E85D04", "#CED4DA")) +
  theme_light() 

# Table of types of algorithms

```

```{r}
# Import the edited table that addresses the identified gaps



# Table of types of algorithms and their frequencies
coded_table %>% 
  count(type_of_algorithm) %>% 
  arrange(desc(n)) %>% 
  kbl() %>% 
  kable_paper("striped")

# Graph of journal fields
coded_table_classes %>% 
  count(journal_field) %>% 
  arrange(desc(n)) %>% 
  ggplot(aes(x=fct_reorder(journal_field, n), y=n)) +
  geom_col(fill="midnightblue") +
  coord_flip() +
  labs(x="Journal Field") +
  theme_light()

# Need to clean and combine categories. For example, Advertising should be under Communication 

coded_table %>% 
  mutate(AI_or_not = if_else(str_detect(type_of_algorithm, "AI"), "Yes", "No")) %>% 
  ggplot(aes(x=AI_or_not)) +
  geom_bar()
```

```{r}
# Rates of algorithm aversion over time
coded_table_classes %>% 
  drop_na(Algorithm_orientations) %>% 
  group_by(Year) %>% 
  count(Algorithm_orientations) %>%
  mutate(prop=n/sum(n)) %>% 
  ggplot(aes(x=Year, y=prop, color=Algorithm_orientations)) +
  geom_line(aes(group=Algorithm_orientations)) +
  geom_point() +
  scale_color_manual(name="Algorithm Orientation",
                    values = c("#9D0208", "#FFBA08", "#E85D04", "#CED4DA"))

```

```{r}
# Subjective vs. objective tasks, self vs. other, algorithm orientations

coded_table_classes %>% 
  count(agent_tasks) %>% 
  arrange(desc(n)) %>% 
  print(n=150)

```

```{r}
# Make a simpler graph of frequencies of outcomes for different human comparisons

coded_table_classes %>% 
  mutate(Algorithm_orientations = case_when(Algorithm_orientations == "Both" ~ "Mixed",
                                            Algorithm_orientations == "Algorithm aversion" ~ "Aversion",
                                            Algorithm_orientations == "Algorithm appreciation" ~ "Appreciation",
                                            Algorithm_orientations == "Neutral" ~ "Neutral")) %>%
  mutate(Algorithm_orientations = fct_relevel(Algorithm_orientations, c("Aversion", "Appreciation", "Mixed", "Neutral"))) %>% 
  group_by(Algorithm_orientations) %>% 
  count(Type_of_human_manipulated) %>% 
  mutate(prop =n/sum(n)) %>% 
  filter(Type_of_human_manipulated %in% c("Experts", "Laypeople")) %>%
  ggplot(aes(x=Type_of_human_manipulated, y=prop, fill=Algorithm_orientations)) +
  geom_col() +
  facet_wrap(~Algorithm_orientations) +
  theme_light() +
  labs(x="Human reference point",
       y="Proportion of articles") +
  scale_y_continuous(breaks = c(0, .1, .2, .3, .4, .5, .6)) +
  scale_fill_manual(name = "Algorithm orientations",
    values = c("#A11E22", "#E8A631","#E8C898", "lightblue")) +
  theme(axis.title = element_text(size = 14),
        legend.position = "none")
```

```{r}
# Year and method
# coded_table_classes %>% 
#   filter(Method %in% c("experiment", "field experiment", "interviews", "mixed-methods", "survey", "review")) %>% 
#   ggplot(aes(x=Year, fill=Method)) +
#   geom_bar()
```

```{r}
# Import updated table
# task_domains <- read_csv("working_table_Oct10.csv")
```

```{r}
# # Graph of task domain frequencies
# relabeled_domains <- task_domains %>% 
#   drop_na(task_domain) %>% 
#   mutate(task_domain = if_else(first_author_last_name == "Hohensinn", "Legal/Ethical decisions", task_domain)) %>% 
#   mutate(task_domain = case_when(task_domain == "Forecasting and Predictive Analysis" ~ "Finance and Predictive Analysis",
#                                  task_domain == "HR/Education decisions" ~ "Career and Education",
#                                  task_domain == "Creative tasks" ~ "Arts and Language",
#                                  task_domain == "Healthcare/Medical decisions" ~ "Healthcare and Medical",
#                                  task_domain == "Legal/Ethical decisions" ~ "Legal and Ethical",
#                                  task_domain == "Customer and community services" ~ "Customer and Public Service",
#                                  task_domain == "Classification/Memory tasks" ~ "Classification and Memory",
#                                  task_domain == "Multiple" ~ "Multiple")) 
# 
# relabeled_domains %>% 
#   count(task_domain) %>% 
#   arrange(desc(n)) %>% 
#   ggplot(aes(x=fct_reorder(task_domain, n), y=n)) +
#   geom_col(fill="midnightblue") +
#   coord_flip() +
#   labs(x="Task Domain") +
#   theme_light() +
#   labs(x="Number of Articles")
# 
# # Would use the following if you wanted to arrange in descending order by frequency of domain
# # ggplot(aes(x = forcats::fct_rev(fct_infreq(task_domain)))) 
# 
# relabeled_domains %>% 
#   drop_na(Algorithm_orientations) %>% 
#   count(Algorithm_orientations) %>% 
#   mutate(prop = n/sum(n))
```


```{r}
# Orientations by Task Domain
results_by_task_domain <- relabeled_domains %>% 
  drop_na(Algorithm_orientations) %>% 
  filter(task_domain != "Multiple") %>% 
  mutate(Algorithm_orientations = fct_relevel(Algorithm_orientations, c("Neutral", "Both", "Algorithm appreciation", "Algorithm aversion"))) %>% 
  ggplot(aes(x = fct_rev(fct_infreq(task_domain)))) +
  geom_bar(aes(fill = Algorithm_orientations), position="stack") +
  coord_flip() +
  labs(x="Task domain",
       y="Number of articles",
       fill="Result",
       tag = "a") +
  theme_light() +
  scale_fill_manual(
                    values = c("#A11E22", "#E8A631","#E8C898", "lightblue"),
                    breaks=c('Algorithm aversion', 'Algorithm appreciation', 'Both', "Neutral"),
                    labels=c("Aversion", "Appreciation", "Mixed", "Neutral")) +
  theme(legend.position = "top",
        legend.key.spacing = unit(1, "mm"),
        legend.title = element_text(size = 10),
        legend.text = element_text(size=8),
        axis.title = element_text(size=14))

results_by_task_domain
```


```{r}
# Just algorithm aversion
algorithm_aversion_by_task_domain <- relabeled_domains %>% 
  drop_na(Algorithm_orientations) %>% 
  group_by(task_domain) %>% 
  count(Algorithm_orientations) %>% 
  mutate(prop = n/sum(n)) %>% 
  filter(Algorithm_orientations == "Algorithm aversion") %>% 
  filter(task_domain != "Multiple") %>% 
  mutate(Algorithm_orientations = fct_relevel(Algorithm_orientations, c("Neutral", "Both", "Algorithm appreciation", "Algorithm aversion"))) %>% 
  ggplot(aes(x=reorder(task_domain, prop), y=prop)) +
  geom_col(fill="#A11E22") +
  geom_hline(yintercept=.5, linetype=2, color="darkgray") +
  coord_flip() +
  theme_light() +
  labs(x="",
       y="Proportion of articles finding algorithm aversion",
       caption = "Dashed line at y = 0.5 indicates the mean rate of algorithm aversion\nacross all articles in the sample",
       tag = "b") +
  theme(axis.title = element_text(size=14))

algorithm_aversion_by_task_domain
  
```

```{r}
# Combine the plots
results_by_task_domain + algorithm_aversion_by_task_domain
```


```{r}
task_domains %>% 
  count(type_of_algorithm) %>% 
  arrange(desc(n))

broad_tech_categories <- task_domains %>% 
  mutate(broad_tech_category = case_when(str_detect(type_of_algorithm, "AI|ChatGPT") ~ "AI",
                                         str_detect(type_of_algorithm, "robot") ~ "robot",
                                         str_detect(type_of_algorithm, "chatbot") ~ "chatbot",
                                         str_detect(type_of_algorithm, "machine learning|machine-learning") ~ "machine learning algorithm",
                                         str_detect(type_of_algorithm, "vehicle|car") ~ "self-driving vehicle")) %>%
  mutate(broad_tech_category = replace_na(broad_tech_category, replace="rule-based algorithm")) %>% 
  mutate(broadest_tech_category = case_when(broad_tech_category == "AI" ~ "AI",
                                            broad_tech_category == "rule-based algorithm" ~ "rule-based algorithm",
                                            broad_tech_category %in% c("chatbot", "robot", "machine learning algorithm", "self-driving vehicle") ~ "other"))

broad_tech_categories %>% 
  count(broadest_tech_category) %>% 
  arrange(desc(n))

# Prevalence of types of algorithms over time
broad_tech_categories %>% 
  mutate(Year = if_else(first_author_last_name == "Chiou", 2021, Year)) %>% 
  group_by(Year) %>% 
  count(broadest_tech_category) %>% 
  ggplot(aes(x=Year, y=n, color=broadest_tech_category)) +
  geom_line(aes(group=broadest_tech_category), size = 1) +
  geom_point(size=3) +
  labs(x="Year",
       y="Number of articles",
       color="Technology") +
  scale_x_continuous(breaks = seq(2015, 2024, by=1)) +
  scale_y_continuous(limits = c(0,30), breaks = seq(0, 30, by=5)) +
  scale_color_npg(breaks=c("AI", "rule-based algorithm", "other"),
                  labels=c("'AI'", "rule-based 'algorithm'", "other")) +
  theme_light() +
  theme(axis.title = element_text(size = 16),
        axis.text = element_text(size=14),
        legend.title = element_blank(),
        legend.text = element_text(size=14))
```

```{r}
final_table <- read_csv("final_table.csv") %>% 
  mutate(task_domain = if_else(str_detect(task_domain, "Ethical"), "Ethical", task_domain),
         task_domain = if_else(str_detect(task_domain, "Community services"), "Public Policy", task_domain),
         task_domain = if_else(str_detect(task_domain, "Creative tasks"), "Creative", task_domain),
         task_domain = if_else(str_detect(task_domain, "Memory tasks"), "Memory", task_domain))

final_table_classes <- final_table %>% 
  mutate(N = as.numeric(N),
         Algorithm_orientations = as.factor(Algorithm_orientations),
         study_design_human_description = as.factor(study_design_human_description)) %>% 
  mutate(Algorithm_orientations = case_when(Algorithm_orientations == "Both" ~ "Mixed",
                                            Algorithm_orientations == "Algorithm aversion" ~ "Aversion",
                                            Algorithm_orientations == "Algorithm appreciation" ~ "Appreciation",
                                            Algorithm_orientations == "Neutral" ~ "Neutral")) %>%
  mutate(Algorithm_orientations = fct_relevel(Algorithm_orientations, c("Aversion", "Appreciation", "Mixed", "Neutral"))) %>% 
  mutate(study_design_human_description = fct_relevel(study_design_human_description, c("Expert", "Laypeople", "Both", "None"))) 


```


```{r}
final_table_results_by_task_domain <- final_table_classes %>% 
  drop_na(Algorithm_orientations) %>% 
  filter(task_domain != "Multiple") %>% 
  mutate(Algorithm_orientations = fct_relevel(Algorithm_orientations, c("Neutral", "Both", "Algorithm appreciation", "Algorithm aversion"))) %>% 
  ggplot(aes(x = fct_rev(fct_infreq(task_domain)))) +
  geom_bar(aes(fill = Algorithm_orientations), position="stack") +
  coord_flip() +
  labs(x="Task domain",
       y="Number of articles in sample",
       fill="Result",
       tag = "a)") +
  theme_light() +
  scale_fill_manual(
                    values = c("#A11E22", "#E8A631","#E8C898", "lightblue"),
                    breaks=c('Algorithm aversion', 'Algorithm appreciation', 'Both', "Neutral"),
                    labels=c("Aversion", "Appreciation", "Mixed", "Neutral")) +
  theme(legend.position = "top",
        legend.key.spacing = unit(1, "mm"),
        legend.title = element_text(size = 10),
        legend.text = element_text(size=8),
        axis.title = element_text(size=14))

final_table_results_by_task_domain
```

```{r}

# Use a function to compute proportions

compute_proportions <- function(data, categorical_var) {
  # Check if the specified variable exists in the data frame
  if (!categorical_var %in% names(data)) {
    stop("The specified variable does not exist in the data frame.")
  }
  
  # Compute proportions
  proportions <- table(data[[categorical_var]]) / nrow(data)
  rounded_proportions = round(proportions, 3)
  
  # Convert to a data frame for easier reading
  proportions_df <- as.data.frame(rounded_proportions)
  colnames(proportions_df) <- c(categorical_var, "Proportion")
  
  return(proportions_df)
}


compute_proportions(final_table_classes, "Algorithm_orientations")


final_table_classes %>% 
  mutate(Method = case_when(Method %in% c("experiment", "field experiment") ~ "experiment",
                            Method %in% c("survey") ~ "survey",
                            Method %in% c("interviews") ~ "interviews",
                            Method %in% c("experiment; interviews", "experiment; survey", "field study; survey", "interview; survey", "interviews; experiment", "mixed-methods", "survey; experiment") ~ "mixed-methods",
                            Method %in% c("Other", "case study", "correlational study", "model", "review", "participatory study design") ~ "other")) %>% 
  count(Method) %>% 
  mutate(prop=n/sum(n)) 

final_table_classes %>% 
  mutate(participant_region_broad = if_else(str_detect(participant_region_broad, ","), "Multiple", participant_region_broad)) %>% 
  count(participant_region_broad) %>% 
  mutate(prop =n/sum(n)) %>% 
  arrange(desc(n))

final_table_classes %>% 
  mutate(Sample = if_else(str_detect(Sample, ","), "Multiple", Sample)) %>% 
  count(Sample) %>% 
  mutate(prop = n/sum(n)) %>% 
  arrange(desc(n))

compute_proportions(final_table_classes, "task_domain")

compute_proportions(final_table_classes, "task_objectivity")

compute_proportions(final_table_classes, "study_design_human_description")
  
```

```{r}
final_table_classes %>% 
  drop_na(Algorithm_orientations) %>% 
  filter(task_domain != "Multiple",
         task_domain != "Other") %>% 
  count(Algorithm_orientations) %>% 
  mutate(prop = n/sum(n)) 

final_table_algorithm_aversion <- final_table_classes %>% 
  drop_na(Algorithm_orientations) %>% 
  filter(task_domain != "Multiple",
         task_domain != "Other") %>% 
  group_by(task_domain) %>% 
  count(Algorithm_orientations) %>% 
  mutate(prop = n/sum(n)) %>% 
  filter(Algorithm_orientations == "Aversion") %>% 
  ggplot(aes(x=reorder(task_domain, prop), y=prop)) +
  geom_col(fill="#A11E22") +
  geom_hline(yintercept=.53, linetype=2, color="darkgray") +
  coord_flip() +
  theme_light() +
  labs(x="Task domain",
       y="Proportion of articles finding algorithm aversion",
       tag = "b)") +
  theme(axis.title = element_text(size=14))

final_table_algorithm_aversion
```

```{r}
final_table_classes %>% 
  mutate(journal_field = if_else(str_detect(journal_field, "HCI"), "HCI and Robotics", journal_field),
         journal_field = if_else(str_detect(journal_field, "Business"), "Business and Management", journal_field)) %>% 
  count(journal_field) %>% 
  rename("Journal Field" = journal_field) %>% 
  arrange(desc(n)) %>% 
  kbl() %>% 
  kable_paper("striped")

# Journal fields
final_table_classes %>% 
    mutate(journal_field = if_else(str_detect(journal_field, "HCI"), "HCI and Robotics", journal_field),
         journal_field = if_else(str_detect(journal_field, "Business"), "Business and Management", journal_field)) %>% 
  count(journal_field) %>% 
  arrange(desc(n)) %>% 
  ggplot(aes(x=fct_reorder(journal_field, n), y=n)) +
  geom_col(fill="midnightblue") +
  coord_flip() +
  labs(x="Journal field",
       y="Number of articles in sample") +
  theme_light()

final_table_classes %>% 
  filter(journal_field == "Interdisciplinary") %>% 
  count(Journal) %>% 
  arrange(desc(n))
```


```{r}
# Publication years
ggplot(final_table_classes, aes(x=Year)) +
  geom_bar(fill="midnightblue") +
  scale_x_continuous(breaks = seq(2015, 2024, by=1)) +
  labs(y="Number of articles in sample") +
  theme_light() +
  theme(axis.title = element_text(size =14),
        panel.grid = element_blank(),
        axis.title.x = element_text(margin = margin(t=20)),
        axis.title.y=element_text(margin = margin(r=20))) 

final_table_classes %>% 
  count(Year)

# Participant regions
final_table_classes %>% 
  count(participant_region_broad) %>% 
  mutate(participant_region_broad = if_else(str_detect(participant_region_broad, ","), "Multiple", participant_region_broad)) %>% 
  ggplot(aes(x=fct_reorder(participant_region_broad, n), y=n)) +
  geom_col(fill="midnightblue") +
  coord_flip() +
  labs(x="Participant region",
       y="Number of articles in sample") +
  theme_light() +
  theme(axis.title = element_text(size =14))
```


```{r}
# Figure of human alternatives by result

# final_table_classes %>% 
#   group_by(Algorithm_orientations) %>% 
#   count(study_design_human_description) %>% 
#   mutate(prop = n/sum(n)) %>% 
#   ggplot(aes(x=study_design_human_description, y=prop, fill=Algorithm_orientations)) +
#   geom_col() +
#   facet_wrap(~Algorithm_orientations) +
#   labs(x="Human alternative",
#        y= "Proportion of articles") +
#   scale_fill_manual(values = c("#A11E22", "#E8A631","#E8C898", "lightblue")) +
#   theme_light() +
#   theme(legend.position = "none",
#         axis.title = element_text(size=14))

final_table_classes %>% 
  filter(Algorithm_orientations == "Appreciation" & study_design_human_description == "Laypeople")

final_table_classes %>% 
  count(study_design_human_description) %>% 
  arrange(desc(n))

# Human alternatives and participant populations

final_table_classes %>% 
  mutate(Sample = if_else(str_detect(Sample, ","), "multiple", Sample)) %>% 
  filter(Sample %in% c("professional", "general public", "college students")) %>% 
  filter(study_design_human_description != "Both") %>% 
  group_by(Sample) %>% 
  count(study_design_human_description) %>% 
  mutate(prop=n/sum(n)) %>% 
  ggplot(aes(x=Sample, y=prop, fill=study_design_human_description)) +
  geom_bar(stat="identity", position="fill") +
  geom_text(aes(label = study_design_human_description), position = position_fill(vjust=0.5), size=2.5) +
  coord_flip() +
  theme(legend.position = "none") +
  labs(x="Participant Population",
       y="Proportions of each type of human alternative")

  

# final_table_classes %>% 
#   mutate(Sample = if_else(str_detect(Sample, ","), "multiple", Sample)) %>% 
#   filter(Sample %in% c("professional", "general public", "college students")) %>% 
#   group_by(Sample) %>% 
#   count(study_design_human_description) %>% 
#   ggballoonplot(x = "study_design_human_description", y = "Sample", size = "n", show.label = TRUE) +
#   labs(x="Human Alternative",
#        y="Participant Population")

  
```

```{r}
# Algorithm orientations across participant populations
final_table_classes %>%
  mutate(Sample = if_else(str_detect(Sample, ","), "multiple", Sample)) %>%
  filter(Sample %in% c("professional", "general public", "college students")) %>%
  mutate(Algorithm_orientations = fct_relevel(Algorithm_orientations, c("Neutral", "Mixed", "Appreciation", "Aversion"))) %>% 
  ggplot(aes(x=Sample, fill = Algorithm_orientations)) +
  geom_bar(position="fill") +
  scale_fill_manual(
                    values = c("#A11E22", "#E8A631","#E8C898", "lightblue"),
                    breaks=c('Aversion', 'Appreciation', 'Mixed', "Neutral"),
                    labels=c("Aversion", "Appreciation", "Mixed", "Neutral")) +
  labs(y="Proportion of articles",
       fill="Result") +
  theme_light() +
  theme(axis.title=element_text(size =14))

```

```{r}
wip_table <- final_table_classes %>% 
  select(Algorithm_orientations, Method, task_objectivity, task_domain, agent_tasks, first_author_last_name) %>%
  rename("First Author" = first_author_last_name,
         "Objectivity" = task_objectivity,
         "Domain" = task_domain,
         "Agent's Task" = agent_tasks,
         "Result" = Algorithm_orientations) %>% 
  mutate(Method = str_to_title(Method)) %>% 
  group_by(Result) %>% 
  slice_sample(prop = .1)

kable(wip_table) %>% 
  kable_paper() %>% 
  collapse_rows(1, valign = "top") %>% 
  add_header_above(c("Study" = 2, "Task Features"=3, " "=1))
```

```{r}
# Read final table from Oct. 24
final_table_Oct24 <- read_csv("final_table_Oct24.csv")
```


```{r}
# Relevel factors
final_table_Oct24_classes <- final_table_Oct24 %>% 
  mutate(participant_region_broad = if_else(str_detect(participant_region_broad, ","), "Multiple", participant_region_broad)) %>% 
  rename(`Participant region` = "participant_region_broad") %>% 
  mutate(`Participant region` = fct_relevel(`Participant region`, c("US", "Europe", "Asia", "Australia", "Middle East", "Multiple", "Unspecified"))) %>%
  mutate(Algorithm_orientations = case_when(Algorithm_orientations == "Both" ~ "Mixed",
                                            Algorithm_orientations == "Algorithm aversion" ~ "Aversion",
                                            Algorithm_orientations == "Algorithm appreciation" ~ "Appreciation",
                                            Algorithm_orientations == "Neutral" ~ "Neutral")) %>%
  mutate(Algorithm_orientations = fct_relevel(Algorithm_orientations, c("Aversion", "Appreciation", "Mixed", "Neutral"))) %>% 
  mutate(Method = case_when(Method %in% c("experiment", "field experiment") ~ "experiment",
                            Method %in% c("survey") ~ "survey",
                            Method %in% c("interviews") ~ "interviews",
                            Method %in% c("experiment; interviews", "experiment; survey", "field study; survey", "interview; survey", "interviews; experiment", "mixed-methods", "survey; experiment") ~ "mixed-methods",
                            Method %in% c("Other", "case study", "correlational study", "model", "review", "participatory study design") ~ "other")) %>% 
  mutate(Method = fct_relevel(Method, c("experiment", "survey", "interviews", "mixed-methods", "other"))) %>% 
  mutate(Sample = if_else(str_detect(Sample, ","), "multiple", Sample)) %>% 
  mutate(Sample = fct_relevel(Sample, c("general public", "college students", "professional", "multiple", "others"))) %>% 
    mutate(task_domain = if_else(task_domain == "Forecasting and Predictive Analysis", "Forecasting/Prediction", task_domain)) %>% 
  mutate(task_objectivity = fct_relevel(task_objectivity, c("Objective", "Subjective", "Combined", "Other"))) %>% 
   mutate(task_domain = if_else(str_detect(task_domain, "Community services"), "Public Service", task_domain),
         task_domain = if_else(str_detect(task_domain, "Creative tasks"), "Creative", task_domain),
         task_domain = if_else(str_detect(task_domain, "Memory tasks"), "Memory", task_domain)) %>% 
  mutate(task_domain = fct_relevel(task_domain, c("Classification", "Creative", "Customer Service", "Education", "Ethical", "Forecasting/Prediction", "Human Resources", "Legal", "Medical/Healthcare", "Memory", "Public Service", "Multiple", "Other"))) %>% 
  mutate(human_alternative = fct_relevel(human_alternative, c("Oneself", "Experts", "Laypeople", "Experts and Laypeople"))) %>% 
  mutate(self_is_subject_of_decision = fct_relevel(self_is_subject_of_decision, c("Yes", "No")))

```

```{r}
final_table_Oct24_classes %>%
  tabyl(Algorithm_orientations, `Participant region`) %>%
  adorn_totals(where = c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl(col.names = c("", "US", "Europe", "Asia", "Australia", "Middle East", "Multiple", "Unspecified", "Total")) %>% 
  add_header_above(c(" " = 1, "Participant region"=7, " "=1)) %>% 
  # row_spec(row=5, bold = TRUE) %>% 
  # column_spec(column=9, bold = TRUE) %>% 
  kable_classic(html_font = "arial")
```
```{r}
# method crosstab
# final_table_Oct24_classes %>%
#   tabyl(Algorithm_orientations, Method) %>%
#   adorn_totals(where = c("row", "col")) %>% 
#   adorn_percentages("col") %>%
#   adorn_pct_formatting(digits = 0) %>%
#   adorn_ns(position="front") %>% 
#   kbl(col.names = c("", "Experiment", "Survey", "Interviews", "Mixed-methods", "Other", "Total"), linesep = "") %>% 
#   add_header_above(c(" " = 1, "Method" = 5, " " = 1)) %>% 
#   kable_classic(html_font = "arial") 
```

```{r}
orientations_by_sample <- table(final_table_Oct24_classes$Algorithm_orientations, final_table_Oct24_classes$Sample)
orientations_by_sample %>% 
  kbl() %>% 
  kable_paper()

# Create a contingency table
contingency_table <- table(final_table_Oct24_classes$Algorithm_orientations, final_table_Oct24_classes$Sample)

# Calculate percentages
percentage_table <- prop.table(contingency_table) * 100

# Combine frequency and percentage
formatted_table <- paste(contingency_table, " (", round(percentage_table, 1), "%)", sep = "")

# Convert to a matrix for better display
formatted_matrix <- matrix(formatted_table, nrow = nrow(contingency_table), byrow = TRUE)
rownames(formatted_matrix) <- rownames(contingency_table)
colnames(formatted_matrix) <- colnames(contingency_table)

# Print the formatted contingency table
formatted_matrix %>% 
  kbl() %>% 
  kable_paper()

# Use Janitor package to make the same table
final_table_Oct24_classes %>%
  tabyl(Algorithm_orientations, Sample) %>%
  adorn_totals(where = c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl(col.names = c("", "General Public", "College Students", "Professionals", "Multiple", "Others", "Total")) %>% 
  add_header_above(c(" "=1, "Participant population"=5, " "=1)) %>% 
  kable_classic(html_font = "arial")
```

```{r}
# Task context crosstab
final_table_Oct24_classes %>%
  tabyl(Algorithm_orientations, task_domain) %>%
  adorn_totals(where = c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl(col.names = c(" ", "Classification", "Creative", "Customer Service", "Education", "Ethical", "Forecasting/Prediction", "Human Resources", "Legal", "Medical/Healthcare", "Memory", "Public Service", "Multiple", "Other", "Total")) %>% 
  add_header_above(c(" " =1, "Task context" = 13, " " = 1)) %>% 
  kable_classic(html_font = "arial") 
```

```{r}
# Task objectivity crosstab
# final_table_Oct24_classes %>%
#   tabyl(Algorithm_orientations, task_objectivity) %>%
#   adorn_totals(where=c("row", "col")) %>% 
#   adorn_percentages("col") %>%
#   adorn_pct_formatting(digits = 0) %>%
#   adorn_ns(position="front") %>% 
#   kbl(col.names = c("", "Objective", "Subjective", "Combined", "Other", "Total")) %>%
#   add_header_above(c(" " =1, "Task objectivity" = 4, " " =1)) %>% 
#   kable_classic(html_font = "arial")
```

```{r}
# Human alternative crosstab
# final_table_Oct24_classes %>%
#   tabyl(Algorithm_orientations, human_alternative) %>%
#   adorn_totals(where=c("row", "col")) %>% 
#   adorn_percentages("col") %>%
#   adorn_pct_formatting(digits = 0) %>%
#   adorn_ns(position="front") %>% 
#   kbl(col.names = c("", "Oneself", "Experts", "Laypeople", "Experts and Laypeople", "Total")) %>%
#   add_header_above(c(" "=1, "Human alternative" = 4, " " = 1)) %>% 
#   kable_classic(html_font = "arial")
```

```{r}
# # Decision impact crosstab
# final_table_Oct24_classes %>%
#   tabyl(Algorithm_orientations, self_is_subject_of_decision) %>%
#   adorn_totals(where=c("row", "col")) %>% 
#   adorn_percentages("col") %>%
#   adorn_pct_formatting(digits = 0) %>%
#   adorn_ns(position="front") %>% 
#   kbl(col.names = c("", "Yes", "No", "Total")) %>%
#   add_header_above(c(" " =1, "Decision impacts oneself" = 2, " " = 1)) %>% 
#   kable_classic(html_font = "arial")
```

```{r}
# final_table_Oct24_classes %>% 
#   count(journal_field) %>% 
#   ggplot(aes(x=fct_reorder(journal_field, n), y=n)) +
#   geom_col(fill="midnightblue") +
#   coord_flip() +
#   labs(x="Journal field",
#        y="Number of articles in sample") +
#   theme_light() +
#   theme(panel.grid = element_blank())
# 
# final_table_Oct24_classes %>% 
#   count(journal_field) %>% 
#   arrange(desc(n)) %>% 
#   ggplot(aes(x=fct_reorder(journal_field, n), y=n)) +
#   geom_col(fill="midnightblue") +
#   coord_flip() +
#   labs(x="Journal field",
#        y="Number of articles in sample") +
#   theme_light() +
#   theme(panel.grid = element_blank())
```

```{r}
# final_table_Oct24_classes %>% 
#   count(participant_region_broad) %>%
#   ggplot(aes(x=fct_reorder(participant_region_broad, n), y=n)) +
#   geom_col(fill="midnightblue") +
#   coord_flip() +
#   labs(x="Participant region",
#        y="Number of articles in sample") +
#   theme_light() +
#   theme(axis.title = element_text(size =14),
#         panel.grid = element_blank()) 
# ```

```{r}
# Human alternatives for each orientation

final_table_Oct26_years %>% 
  group_by(`Algorithm Orientation`) %>% 
  count(human_alternative) %>% 
  mutate(prop = n/sum(n)) %>% 
  ggplot(aes(x=human_alternative, y=prop, fill=`Algorithm Orientation`)) +
  geom_col() +
  facet_wrap(~`Algorithm Orientation`) +
  labs(x="Human alternative",
       y= "Proportion of articles") +
  scale_fill_manual(values = c("#A11E22", "#E8A631","#E8C898", "lightblue")) +
  theme_light() +
  theme(legend.position = "none",
        axis.title = element_text(size=14),
        panel.grid = element_blank(),
        strip.text = element_text(size = 12),
        axis.title.x = element_text(margin = margin(t=20)),
        axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)))
```


```{r}
# Human alternatives for each orientation
# WS hacking around

#cols

cols_subset = c("Participant region", "Method", "Sample", "task_domain", "task_objectivity", "human_alternative", "self_is_subject_of_decision")

test_list <- list()

# Function to relabel axes
format_variable_name <- function(var_name) {
  # Replace underscores with spaces
  formatted_name <- gsub("_", " ", var_name)
  
  # Capitalize the first letter
  formatted_name <- sub("^(.)", "\\U\\1", formatted_name, perl = TRUE)
  
  return(formatted_name)
}

#this works (ish):
for (i in 1:length(cols_subset)) {
  #print(variable)
  variable <- cols_subset[i]

test_list[[i]] <- final_table_Oct24_classes %>% 
  group_by(Algorithm_orientations) %>% 
  count(!!sym(variable)) %>%
  mutate(prop = n/sum(n)) %>% 
  ggplot(aes(x=!!sym(variable), y=prop, fill=Algorithm_orientations)) +
  geom_col() +
  facet_wrap(~Algorithm_orientations) +
  scale_fill_manual(values = c("#A11E22", "#E8A631","#E8C898", "lightblue")) +
  ylim(c(0,1)) +
  theme_light() +
  theme(legend.position = "none",
        axis.title = element_text(size=14),
        panel.grid = element_blank(),
        strip.text = element_text(size = 12),
        axis.title.x = element_text(margin = margin(t=20)),
        axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) +
  labs(x=format_variable_name(variable),
       y = "Proportion of articles")

}
test_list[[1]]
test_list[[2]]
test_list[[3]]
test_list[[5]]
test_list[[6]]
test_list[[7]]
```


```{r}
# testplot <- final_table_Oct24_classes %>% 
#   group_by(Algorithm_orientations) %>% 
#   #count(variable) %>%
#   count(participant_region_broad) %>%
#   mutate(prop = n/sum(n)) %>% 
#   ggplot(aes(x=variable, y=prop, fill=Algorithm_orientations)) +
#   geom_col() +
#   facet_wrap(~Algorithm_orientations) +
#   labs(x=format,
#        y= "Proportion of articles") +
#   scale_fill_manual(values = c("#A11E22", "#E8A631","#E8C898", "lightblue")) +
#   theme_light() +
#   theme(legend.position = "none",
#         axis.title = element_text(size=14),
#         panel.grid = element_blank(),
#         strip.text = element_text(size = 12),
#         axis.title.x = element_text(margin = margin(t=20)),
#         axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)))
# 
# testplot
# 
# test_list[[1]]
# test_list[[2]]
```

```{r}
# Make task domain plot to fix the cluttered x-axis

task_domain_cross_tab_plot <- final_table_Oct24_classes %>% 
  group_by(Algorithm_orientations) %>% 
  count(task_domain) %>%
  mutate(prop = n/sum(n)) %>% 
  ggplot(aes(x=task_domain, y=prop, fill=Algorithm_orientations)) +
  geom_col() +
  facet_wrap(~Algorithm_orientations) +
  scale_fill_manual(values = c("#A11E22", "#E8A631","#E8C898", "lightblue")) +
  ylim(c(0,1)) +
  theme_light() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90, vjust = 1, hjust=1),
        axis.title = element_text(size=14),
        panel.grid = element_blank(),
        strip.text = element_text(size = 12),
        axis.title.x = element_text(margin = margin(t=20)),
        axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) +
  labs(x="Task domain",
       y = "Proportion of articles")

task_domain_cross_tab_plot
```


```{r}
final_table_Oct24_classes %>% 
  filter(task_domain != "Multiple",
         task_domain != "Other") %>% 
  group_by(task_domain) %>% 
  count(Algorithm_orientations) %>% 
  mutate(prop = n/sum(n)) %>% 
  filter(Algorithm_orientations == "Aversion") %>% 
  ggplot(aes(x=reorder(task_domain, prop), y=prop)) +
  geom_col(fill="#A11E22") +
  geom_hline(yintercept=.51, linetype=2, color="darkgray") +
  coord_flip() +
  ylim(c(0,1)) +
  theme_light() +
  labs(x="Task domain",
       y="Proportion of articles finding algorithm aversion",
       tag = "b)") +
  theme(axis.title = element_text(size=14),
        panel.grid = element_blank(),
        axis.title.x = element_text(margin = margin(t=20)))

final_table_Oct24_classes %>% 
  filter(task_domain != "Multiple",
         task_domain != "Other") %>% 
  group_by(task_domain) %>% 
  count(Algorithm_orientations) %>% 
  mutate(prop = n/sum(n)) %>% 
  filter(Algorithm_orientations == "Appreciation") %>% 
  ggplot(aes(x=reorder(task_domain, prop), y=prop)) +
  geom_col(fill="#E8A631") +
  geom_hline(yintercept=.12, linetype=2, color="black") +
  coord_flip() +
  ylim(c(0,1)) +
  theme_light() +
  labs(x="Task domain",
       y="Proportion of articles finding algorithm appreciation",
       tag = "c)") +
  theme(axis.title = element_text(size=14),
        panel.grid = element_blank(),
        axis.title.x = element_text(margin = margin(t=20)))
```

```{r}

final_table_Oct24_classes %>% 
  filter(task_domain != "Multiple",
         task_domain != "Other") %>% 
  mutate(Algorithm_orientations = fct_relevel(Algorithm_orientations, c("Neutral", "Mixed", "Appreciation", "Aversion"))) %>% 
  ggplot(aes(x = fct_rev(fct_infreq(task_domain)))) +
  geom_bar(aes(fill = Algorithm_orientations), position="stack") +
  coord_flip() +
  labs(x="Task domain",
       y="Number of articles in sample",
       fill="Result",
       tag = "a)") +
  theme_light() +
  scale_fill_manual(
                    values = c("#A11E22", "#E8A631","#E8C898", "lightblue"),
                    breaks=c('Aversion', 'Appreciation', 'Mixed', "Neutral"),
                    labels=c("Aversion", "Appreciation", "Mixed", "Neutral")) +
  theme(legend.position = "top",
        legend.key.spacing = unit(1, "mm"),
        legend.title = element_blank(),
        legend.text = element_text(size=8),
        axis.title = element_text(size=14),
        panel.grid = element_blank())
```

```{r}
# # Function to make cross-tab figures
# cross_tab_vars <- final_table_Oct24_classes %>% 
#   select(Algorithm_orientations, participant_region_broad, Method, Sample, task_domain, task_objectivity, human_alternative, self_is_subject_of_decision)
# 
# plot.cross_tab <- function(x=cross_tab_vars) {
#   cols <- colnames(cross_tab_vars)
#   cols <- cols[-1]
#   for (col in cols) {
#     plot <- cross_tab_vars %>% 
#       group_by(Algorithm_orientations) %>% 
#       count(cross_tab_vars[[col]]) %>% 
#       mutate(prop=n/sum(n)) %>% 
#       ggplot(aes(x=cross_tab_vars[[col]], y=prop)) +
#       geom_col() +
#       facet_wrap(~Algorithm_orientations)
#   print(plot)
#   }
# }
```

```{r}
final_table_Oct24_classes %>% 
  count(self_is_subject_of_decision) %>% 
  mutate(prop = n/sum(n))
```
```{r}
final_table_classes %>% 
  group_by(task_domain) %>% 
  count(Algorithm_orientations) %>% 
  mutate(prop=n/sum(n)) %>% 
  filter(Algorithm_orientations %in% c("Aversion", "Appreciation")) %>% 
  pivot_wider(id_cols = "task_domain", names_from = "Algorithm_orientations", values_from = "prop") %>% 
  group_by(task_domain) %>% 
  mutate(aversion_to_appreciation_ratio = Aversion/Appreciation) %>% 
  arrange(desc(aversion_to_appreciation_ratio)) %>% 
  filter(!is.na(aversion_to_appreciation_ratio)) %>% 
  ggplot(aes(x=fct_reorder(task_domain, aversion_to_appreciation_ratio), y=aversion_to_appreciation_ratio)) +
  geom_col() +
  labs(x="Task domain",
       y="Ratio of rate of aversion to rate of appreciation") +
  coord_flip()
```

```{r}
# Import data table with outcome categories and type of algorithm categories
final_table_Oct26 <- read_csv("final_table_Oct26.csv") %>%
  mutate(participant_region_broad = if_else(str_detect(participant_region_broad, ","), "Multiple", participant_region_broad)) %>% 
  rename(`Participant region` = "participant_region_broad") %>% 
  mutate(`Participant region` = fct_relevel(`Participant region`, c("US", "Europe", "Asia", "Australia", "Middle East", "Multiple", "Unspecified"))) %>%
  mutate(Algorithm_orientations = fct_relevel(Algorithm_orientations, c("Aversion", "Appreciation", "Ambivalence", "Apathy"))) %>% 
  mutate(Method = case_when(Method %in% c("experiment", "field experiment") ~ "experiment",
                            Method %in% c("survey") ~ "survey",
                            Method %in% c("interviews") ~ "interviews",
                            Method %in% c("experiment; interviews", "experiment; survey", "field study; survey", "interview; survey", "interviews; experiment", "mixed-methods", "survey; experiment") ~ "mixed-methods",
                            Method %in% c("Other", "case study", "correlational study", "model", "review", "participatory study design") ~ "other")) %>% 
  mutate(Method = fct_relevel(Method, c("experiment", "survey", "interviews", "mixed-methods", "other"))) %>% 
  mutate(Sample = if_else(str_detect(Sample, ","), "multiple", Sample)) %>% 
  mutate(Sample=ifelse(Sample == "others", "general public", Sample)) %>% 
  mutate(Sample = fct_relevel(Sample, c("general public", "college students", "professional", "multiple"))) %>% 
  mutate(task_objectivity = fct_relevel(task_objectivity, c("Objective", "Subjective", "Combined"))) %>% 
   mutate(
         task_domain = if_else(str_detect(task_domain, "Memory tasks"), "Memory", task_domain)) %>% 
  mutate(task_domain = fct_relevel(task_domain, c("Classification", "Creative", "Customer Service", "Education", "Ethical", "Forecasting/Prediction", "Human Resources", "Legal", "Medical/Healthcare", "Memory", "Public Service", "Multiple", "Other"))) %>% 
  mutate(human_alternative = fct_relevel(human_alternative, c("Oneself", "Experts", "Laypeople", "Experts and Laypeople"))) %>% 
  mutate(`Outcome Categories` = ifelse(`Outcome Categories` == "Emotional and Affective Responses", "Perceptions and Attitudes Toward Algorithms", `Outcome Categories`)) %>% 
  mutate(`Outcome Categories` = fct_relevel(`Outcome Categories`, c("Behavioral Choices and Preferences", "Perceptions and Attitudes Toward Algorithms", "Trust and Ethical Evaluations", "Performance and Accuracy Metrics", "Multiple"))) %>% 
  rename(`Algorithm Orientation` = "Algorithm_orientations") %>% 
  mutate(`Type of algorithm categories` = fct_relevel(`Type of algorithm categories`, c("General AI/algorithm", "Decision-making models/systems/tools", "Task-specific models/systems/tools", "Generative AI", "Multiple", "Others (e.g., robots/chatbots/computers)")))
# Merge year column of old data with FINAL data

article_years <- final_table_classes %>% 
  select(first_author_last_name, title, Year) %>% 
  filter(first_author_last_name != "Shaikh")

final_table_Oct26_years <- full_join(final_table_Oct26, article_years, by= c("first_author_last_name", "title")) %>% 
  filter(!is.na(`theory and key concepts`)) %>% 
  relocate(Year, .before = "theory and key concepts")  

# Edits
final_table_Oct26_years[144, 22] = "Experts and Laypeople"
final_table_Oct26_years[9, 19] = "Forecasting/Prediction"
final_table_Oct26_years[9, 21] = "Apathy"
final_table_Oct26_years[39, 21] = "Aversion"

```

```{r}
# Cross-tabs for...

# Orientation vs. outcome types
final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, `Outcome Categories`) %>%
  adorn_totals(where = c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl(col.names = c("Algorithm\nOrientation", "Behavioral Choices", "Perceptions and Attitudes", "Trust/Ethical\nEvaluations", "Performance Metrics", "Multiple", "Total")) %>% 
  add_header_above(c(" " = 1, "Outcome Type"=5, " "=1)) %>% 
  # row_spec(row=5, bold = TRUE) %>% 
  # column_spec(column=9, bold = TRUE) %>% 
  kable_classic() %>% 
  save_kable("orientations_outcomes.png")
```

```{r}
# Orientation vs. task objectivity 
final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, task_objectivity) %>%
  adorn_totals(where=c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl(col.names = c("", "Objective", "Subjective", "Combined", "Total")) %>%
  add_header_above(c(" " =1, "Task objectivity" = 3, " " =1)) %>% 
  kable_classic()
```

```{r}
# Orientation vs. sample 
final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, Sample) %>%
  adorn_totals(where=c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl(col.names = c("Algorithm Orientation", "General Public", "College Students", "Professionals", "Multiple", "Total")) %>%
  add_header_above(c(" "=1, "Sample" = 4, " " = 1)) %>%
```


```{r}
kable_classic()
```
```{r}
# Orientation vs. algorithm types 
final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, `Type of algorithm categories`) %>%
  adorn_totals(where=c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl(col.names = c("Algorithm Orientation", "General algorithm", "Decision-making", "Task-specific", "Generative AI", "Multiple", "Others", "Total")) %>% 
  add_header_above(c(" " =1, "Algorithm type" = 6, " " =1)) %>% 
  kable_classic()
```

```{r}
# Orientation vs. participant region
final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, `Participant region`) %>%
  adorn_totals(where=c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl() %>% 
  add_header_above(c(" " =1, "Participant region" = 7, " " =1)) %>% 
  kable_classic()
```
```{r}
# Orientation vs. region 
final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, `Participant region`) %>%
  adorn_totals(where=c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl() %>%
  add_header_above(c(" "=1, "Region" = 7, " " = 1)) %>% 
  kable_classic()
```

```{r}
# Orientation vs. human alternative

final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, human_alternative) %>%
  adorn_totals(where=c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl() %>% 
  add_header_above(c(" " =1, "Human alternative" = 4, " " =1)) %>% 
  kable_classic()
```

```{r}
# Orientation vs. task domain
# 1st section
final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, task_domain) %>%
  adorn_totals(where=c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kable(longtable = TRUE) %>% 
  add_header_above(c(" " =1, "Task function" = 13, " " =1)) %>% 
  remove_column(c(9:15)) %>% 
  kable_classic() 

# 2nd section

final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, task_domain) %>%
  adorn_totals(where=c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kable(longtable = TRUE) %>% 
  remove_column(c(2:8)) %>% 
  add_header_above(c(" " =1, "Task function" = 6, " " =1)) %>% 
  kable_classic() 

# Orientation vs. Method 

final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, Method) %>%
  adorn_totals(where = c("row", "col")) %>%
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>%
  kbl(col.names = c("", "Experiment", "Survey", "Interviews", "Mixed-methods", "Other", "Total"), linesep = "") %>%
  add_header_above(c(" " = 1, "Method" = 5, " " = 1)) %>%
  kable_classic()

# Orientation vs. decision impact

final_table_Oct26_years %>%
  tabyl(`Algorithm Orientation`, self_is_subject_of_decision) %>%
  adorn_totals(where=c("row", "col")) %>% 
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 0) %>%
  adorn_ns(position="front") %>% 
  kbl(col.names = c("", "Yes", "No", "Total")) %>%
  add_header_above(c(" " =1, "Decision impacts oneself" = 2, " " = 1)) %>% 
  kable_classic()
```

```{r}
# Make figures tracking patterns over time

```

```{r}
cols_subset_figures = c("Participant region", "Method", "Sample", "task_domain", "task_objectivity", "human_alternative", "self_is_subject_of_decision")

for (i in 1:length(cols_subset_figures)) {
  #print(variable)
  variable <- cols_subset_figures[i]

test_list[[i]] <- final_table_Oct26_years %>% 
  group_by(`Algorithm Orientation`) %>% 
  count(!!sym(variable)) %>%
  mutate(prop = n/sum(n)) %>% 
  ggplot(aes(x=!!sym(variable), y=prop, fill=`Algorithm Orientation`)) +
  geom_col() +
  facet_wrap(~`Algorithm Orientation`) +
  scale_fill_manual(values = c("#A11E22", "#E8A631","#E8C898", "lightblue")) +
  ylim(c(0,1)) +
  theme_light() +
  theme(legend.position = "none",
        axis.title = element_text(size=14),
        panel.grid = element_blank(),
        strip.text = element_text(size = 12),
        axis.title.x = element_text(margin = margin(t=20)),
        axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0))) +
  labs(x=format_variable_name(variable),
       y = "Proportion of articles")

}

test_list[[5]]
test_list[[3]]
```
```{r}
final_table_Oct26_years %>% 
  count(`Algorithm Orientation`) %>% 
  mutate(prop=n/sum(n))

final_table_Oct26_years %>% 
  count(Method) %>% 
  arrange(desc(n))

final_table_Oct26_years %>% 
  count(`Participant region`) %>% 
  arrange(desc(n))

final_table_Oct26_years %>% 
  count(Sample) %>% 
  mutate(prop = n/sum(n)) %>% 
  arrange(desc(n))

final_table_Oct26_years %>% 
  count(task_domain) %>% 
  mutate(prop = n/sum(n)) %>% 
  arrange(desc(n))

final_table_Oct26_years %>% 
  count(task_objectivity) %>% 
  mutate(prop = n/sum(n)) %>% 
  arrange(desc(n))

final_table_Oct26_years %>% 
  count(human_alternative) %>% 
  mutate(prop = n/sum(n)) %>% 
  arrange(desc(n))

final_table_Oct26_years %>% 
  count(self_is_subject_of_decision) %>% 
  mutate(prop = n/sum(n)) %>% 
  arrange(desc(n))
```
```{r}
final_table_Oct26_years %>% 
  filter(`Algorithm Orientation` == "Apathy")
```

```{r}
# Rates of algorithm aversion for each combination of human alternative and population subgroup

aversion_human_factors <- final_table_Oct26_years %>% 
  filter(Sample %in% c("professional", "general public", "college students")) %>% 
  filter(human_alternative != "Experts and Laypeople") %>% 
  group_by(Sample, human_alternative) %>% 
  count(`Algorithm Orientation`) %>% 
  mutate(aversion_rate=n/sum(n)) %>% 
  filter(`Algorithm Orientation` == "Aversion")

human_factors <- final_table_Oct26_years %>% 
  filter(Sample %in% c("professional", "general public", "college students")) %>% 
  filter(human_alternative != "Experts and Laypeople") %>% 
  group_by(Sample) %>% 
  count(human_alternative) %>% 
  mutate(prop=n/sum(n)) 
human_factors

human_factors_by_aversion <- full_join(human_factors, aversion_human_factors, by=c("Sample", "human_alternative"))

ggplot(human_factors_by_aversion, aes(x=Sample, y=prop, fill=aversion_rate)) +
  geom_bar(stat="identity", position="fill") +
  geom_text(aes(label = human_alternative), position = position_fill(vjust=0.5), color="white") +
  coord_flip() +
  theme_light() +
  theme(panel.grid = element_blank()) +
  labs(x="Participant subgroup",
       y="Proportions of each type of human alternative") +
  scale_fill_continuous(high = "#132B43", low = "#56B1F7")
```

```{r}
# Make a similar figure but for tasks? Fill indicates the intensity of the orientation, but that doesn't really make sense
orientation_by_tasks <- final_table_Oct26_years %>% 
  group_by(task_domain) %>% 
  count(`Algorithm Orientation`) %>% 
  mutate(prop=n/sum(n)) %>% 
  select(-n)

domain_counts <- final_table_Oct26_years %>% 
  count(task_domain) 

mean(domain_counts$n)

orientation_rates_by_task <- full_join(orientation_by_tasks, domain_counts, by=c("task_domain"))

orientation_rates_by_task %>% 
  filter(task_domain %in% c("Forecasting/Prediction", "Medical/Healthcare", "Human Resources", "Creative", "Ethical", "Education", "Customer Service", "Legal")) %>% 
  ggplot(aes(x=fct_reorder(task_domain, n), y=n, fill=prop)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~`Algorithm Orientation`) +
  theme_light() +
  theme(panel.grid = element_blank()) +
  labs(x="Task domain",
       y="Number of articles",
       fill=paste("Proportion of articles\nconcluding", `Algorithm Orientation`)) 

```
```{r}
appreciation_tasks <- final_table_Oct26_years %>% 
  group_by(task_domain) %>% 
  count(`Algorithm Orientation`) %>% 
  mutate(appreciation_rate=n/sum(n)) %>% 
  filter(`Algorithm Orientation` == "Appreciation")

appreciation_rates_by_task <- full_join(appreciation_tasks, domain_counts, by=c("task_domain"))

appreciation_rates_by_task %>% 
  filter(task_domain %in% c("Forecasting/Prediction", "Medical/Healthcare", "Human Resources", "Creative", "Customer Service")) %>%
  ggplot(aes(x=fct_reorder(task_domain, n.y), y=n.y, fill=appreciation_rate)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  theme(panel.grid = element_blank()) +
  labs(x="Task domain",
       y="Number of articles",
       fill="Proportion of articles\nconcluding appreciation") +
  scale_fill_continuous(high = "#E8A631", low = "#EEDBBD")
```

```{r}
ambivalence_tasks <- final_table_Oct26_years %>% 
  group_by(task_domain) %>% 
  count(`Algorithm Orientation`) %>% 
  mutate(ambivalence_rate=n/sum(n)) %>% 
  filter(`Algorithm Orientation` == "Ambivalence")

ambivalence_rates_by_task <- full_join(ambivalence_tasks, domain_counts, by=c("task_domain"))

ambivalence_rates_by_task %>% 
  filter(task_domain %in% c("Forecasting/Prediction", "Medical/Healthcare", "Human Resources", "Creative", "Ethical", "Classification")) %>% 
  # filter(task_domain %in% c("Forecasting/Prediction", "Medical/Healthcare", "Human Resources", "Creative", "Ethical", "Education", "Customer Service", "Legal")) %>% 
  ggplot(aes(x=fct_reorder(task_domain, n.y), y=n.y, fill=ambivalence_rate)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  theme(panel.grid = element_blank()) +
  labs(x="Task domain",
       y="Number of articles",
       fill="Proportion of articles\nconcluding ambivalence") +
  scale_fill_continuous(high = "darkred", low = "#FFBEB2")
```
```{r}
final_table_Oct26_years %>% 
  drop_na(`Algorithm Orientation`) %>%
  filter(task_domain != "Multiple") %>% 
  mutate(`Algorithm Orientation` = fct_relevel(`Algorithm Orientation`, c("Apathy", "Ambivalence", "Appreciation", "Aversion"))) %>% 
  ggplot(aes(x = fct_rev(fct_infreq(task_domain)))) +
  geom_bar(aes(fill = `Algorithm Orientation`), position="stack") +
  coord_flip() +
  labs(x="Task function",
       y="Number of articles in sample",
       fill="Orientation", 
       tag = "a)")+
  theme_light() +
  scale_fill_manual(
                    breaks=c('Aversion', 'Appreciation', 'Ambivalence', "Apathy"),
                    labels=c("Aversion", "Appreciation", "Ambivalence", "Apathy"),
                    values = c("#A11E22", "#E8A631","#E8C898", "lightblue")) +
  theme(panel.grid = element_blank(),
        legend.position = "top",
        legend.key.spacing = unit(1, "mm"),
        legend.title = element_text(size = 10),
        legend.text = element_text(size=8),
        axis.title = element_text(size=14),
        axis.title.x = element_text(margin = margin(t=20)),
        axis.title.y = element_text(margin = margin(r=20)))
```
```{r}
final_table_Oct26_years %>% 
  group_by(task_domain) %>% 
  count(`Algorithm Orientation`) %>% 
  mutate(prop = n/sum(n)) %>% 
  filter(`Algorithm Orientation` == "Aversion") %>% 
  filter(task_domain != "Multiple",
         task_domain != "Other") %>% 
  ggplot(aes(x=reorder(task_domain, prop), y=prop)) +
  geom_col(fill="#A11E22") +
  geom_hline(yintercept=.52, linetype=2, color="darkgray") +
  coord_flip() +
  theme_light() +
  labs(x="Task function",
       y="Proportion of articles concluding aversion",
       tag = "b)") +
  theme(axis.title = element_text(size=14),
        axis.title.x = element_text(margin = margin(t=20)),
        axis.title.y = element_text(margin = margin(r=20)),
        panel.grid = element_blank())
```

```{r}
main_table <- read_csv("main_table.csv", skip = 1)

pdf("main_table_10.31.pdf", width=11, height = 8.5)


kable(main_table) %>% 
  add_header_above(c("General" = 2, 
                     "Study Characteristics" = 3, 
                     "Human Factors" = 3, 
                     "Algorithm Factors" = 1, 
                     "Task Factors" = 2, 
                     "Outcome Factors" = 2, 
                     "Findings" = 2)) %>% 
  kable_classic() %>% 
  save_kable("kable_table.pdf")

                     
```

