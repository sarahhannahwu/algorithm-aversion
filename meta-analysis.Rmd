---
title: "meta-analysis"
output: html_document
date: "2024-08-13"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import libraries

```{r}
library(tidyverse)
library(dplyr)
```

## Import csv of coded search results

```{r}
coded_articles <- read_csv("Inclusion_exclusion coding - mendeley_export.csv")
```

```{r}
# Identify remaining duplicates. These were all coded as irrelevant.

titles_abstracts <- coded_articles %>% 
  select(title, abstract)  
  
duplicates <- titles_abstracts %>% 
  group_by_all() %>% 
  filter(n() > 1) %>% 
  ungroup()

# Limit to unique entries
# distinct <- coded_articles %>% 
#   distinct(title) %>% 
#   filter()

# Count number of included articles
coded_articles %>% 
  count(`Inclusion: (1) Yes (2) No, not English, (3) No, not focused on AI vs. human, (4) No, other reasons`)

# Filter for relevant articles (1st round of coding). Manually go through and remove any remaining duplicates. (Initially not identified because of slight punctuation and case differences.) Use str_to_title() to convert all titles to title case
relevant_articles <- coded_articles %>% 
  filter(`Inclusion: (1) Yes (2) No, not English, (3) No, not focused on AI vs. human, (4) No, other reasons` == 1) %>% 
  filter(!(ID %in% c("ID-1355", "ID-291", "ID-264", "ID-109", "ID-137", "ID-1295", "ID-1342", "ID-144", "ID-1134", "ID-127", "ID-459", "ID-025", "ID-023", "ID-1272", "ID-1322", "ID-1444"))) %>% 
  mutate(title = str_to_title(title))


write_csv(relevant_articles, "2024_complete_list.csv")

```

```{r}
# Count proportion of each type of method for the relevant articles
relevant_articles %>% 
  count(`Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews`) 

# Look at represented domains. It might be more informative to group into fewer buckets. For example, 'healthcare' and 'medical' could be combined into one category. 'Art' and 'visual art' could be combined. 
relevant_articles %>% 
  count(domain) %>% 
  print(n = 90)

# See the range of publication years
relevant_articles %>% 
  summarize(oldest_paper = min(year),
            newest_paper = max(year))

write_csv(relevant_articles, "1st_round_coding.csv")
```

```{r}
# Import spreadsheet of articles from ICA 2023 meta-analysis
old_articles <- read_csv("2nd_round_coding_2023_ICA.csv") %>% 
  rename("title" = "Article name",
         "domain" = "Task Domain",
         "first_author_last_name" = "First Author Last Name",
         "notes" = "Notes")

# See how many unique entries I added. 
new_articles <- anti_join(relevant_articles, old_articles, by = "title")

# Recode methods and domains in new list
# Last line uses string manipulation to only include first author's last name
new_articles_recoded <- new_articles %>% 
  mutate(Method = case_when(`Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "1" ~ "Quantitative",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "2" ~ "Qualitative",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "3" ~ "Review",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` %in% c("1, 2", NA) ~ "Other")) %>% 
  relocate(Method, .after = `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews`) %>% 
  mutate(first_author_last_name = if_else(str_detect(author, "and") == TRUE, str_extract(author, "\\b(\\w+)\\b(?=\\s+and\\b)"), str_extract(author, "\\b([\\w-]+)\\b(?=[^\\w-]*$)")))

# Check domains from old list
old_articles %>% 
  count(Field)

old_articles %>% 
  filter(Field == "business") %>% 
  print(n = 34)

# Check domains from new list
new_articles_recoded %>% 
  count(domain) %>% 
  print(n = 82)

# Check distribution of publication years
ggplot(new_articles_recoded, aes(x=year)) +
  geom_histogram(bins = 7, color = "white")
  

```

```{r}
# Join old and new list
merged_list <- bind_rows(old_articles, new_articles_recoded)

# Delete unnecessary columns
merged_list_cleaned <- merged_list %>% 
  select(-c(author, `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews`, `Article ID_Old`, `Inclusion: (1) Yes (2) No, not English, (3) No, not focused on AI vs. human, (4) No, other reasons`))


# Export for use in Google Sheets
write_csv(merged_list_cleaned, "merged_list_8.19.24.csv")

```

```{r}
# Create a merged list called '2024 + 2023 first round of coding' with duplicates removed. This will probably be a smaller file

# Import csv
ICA_1st_round_coding <- read_csv("2023_1st_round_coding.csv") %>% 
  rename("title" = "Article Title",
         "first_author_last_name" = "First Author Last Name") %>% 
  mutate(title = str_to_title(title))

# See how many unique entries I added.
unique_new_based_on_ICA_1st_round <- anti_join(relevant_articles, ICA_1st_round_coding, by = "title") 

unique_new_recoded <- unique_new_based_on_ICA_1st_round %>% 
  mutate(Method = case_when(`Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "1" ~ "Quantitative",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "2" ~ "Qualitative",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` == "3" ~ "Review",
                                    `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews` %in% c("1, 2", NA) ~ "Other")) %>% 
  relocate(Method, .after = `Method: (1) quantitative, (2) qualitative, (3) meta analysis, reviews`) %>% 
  mutate(first_author_last_name = if_else(str_detect(author, "and") == TRUE, str_extract(author, "\\b(\\w+)\\b(?=\\s+and\\b)"), str_extract(author, "\\b([\\w-]+)\\b(?=[^\\w-]*$)"))) 

# There are 185 unique articles

# Join ICA 1st round coding + unique entries

bind_rows(ICA_1st_round_coding, unique_new_based_on_ICA_1st_round)

```

